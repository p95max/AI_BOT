Local AI Chat Application
A local AI-powered chat application built with Python and CustomTkinter for a modern desktop experience.
This project integrates with Ollama for running local language models such as LLaMA2, Mistral, and Gemma,
ensuring privacy and data security by keeping all processing offline.

Features:

- Local AI Models: Powered by Ollama, supporting models like LLaMA2, Mistral, and Gemma.
- Modern UI: Built with CustomTkinter, providing a macOS-style interface.
- Model Selection: Easily switch between available models.
- Chat History: Keeps track of conversations and allows clearing history.
- No Internet Required: Everything runs locally, ensuring data privacy.

Technologies Used:

- Python: The core programming language for this app.
- CustomTkinter: A modern wrapper for Tkinter, providing a sleek and responsive UI.
- Ollama API: For integrating with local language models.
- Requests: To handle API requests to Ollama.
- GitHub: For version control and hosting the project.

  More in requirements.txt
